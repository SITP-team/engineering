#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jul 17 12:33:39 2025
@author: chunlongyu

"""

import time
import json
import uuid
import pythoncom
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(
    0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)

from src.utils.api_utils import make_api_request
from src.utils.json_utils import extract_json_from_response
from src.utils.graph_preprocessor import convert_zero_capacity_conveyors_to_edges
from src.generation.simtalk_generator import json_to_simtalk
from src.generation.plant_simulator import create_plant_simulation_model
from src.visualization.visualize import ProductionLineVisualizer
from src.visualization.visualization_confirm import visualize_and_confirm
from src.config.dynamic_prompt import DynamicPromptGenerator
from src.generation.standardization import standardize_text

# å¯¹è¯å†å²å­˜å‚¨
conversation_history = []

print("ğŸ¯ æ¬¢è¿ä½¿ç”¨ Plant Simulation è‡ªåŠ¨åŒ–å»ºæ¨¡å·¥å…·ï¼")
print("ğŸ“ è¯·è¾“å…¥æ‚¨çš„ç”Ÿäº§çº¿æè¿°ï¼Œæˆ‘å°†è‡ªåŠ¨ç”ŸæˆPlant Simulationæ¨¡å‹")
print("ğŸ’¡ ä¾‹å¦‚ï¼šæºèŠ‚ç‚¹æ¯10åˆ†é’Ÿç”Ÿæˆä¸€ä¸ªäº§å“ï¼ŒåŠ å·¥å·¥ä½å¤„ç†æ—¶é—´5åˆ†é’Ÿï¼Œç¼“å†²åŒºå®¹é‡10...")
print("ğŸšª è¾“å…¥ 'exit' æˆ– 'quit' å¯é€€å‡ºç¨‹åº\n")

# è°ƒè¯•æ¨¡å¼å¼€å…³ - è®¾ç½®ä¸ºTrueå¯æŸ¥çœ‹AIå®Œæ•´æ€è€ƒè¿‡ç¨‹
DEBUG_MODE = 1

# è®¾ç½®Tcl/Tkç¯å¢ƒå˜é‡ï¼ˆè§£å†³pyenvå®‰è£…çš„Python Tclè·¯å¾„é—®é¢˜ï¼‰
import os

python_home = r"C:\Users\a1387\.pyenv\pyenv-win\versions\3.13.0"
os.environ["TCL_LIBRARY"] = os.path.join(python_home, "tcl", "tcl8.6")
os.environ["TK_LIBRARY"] = os.path.join(python_home, "tcl", "tk8.6")

# åˆå§‹åŒ–COMç¯å¢ƒ
pythoncom.CoInitialize()
try:
    while True:
        prompt_generator = DynamicPromptGenerator()
        user_input = input("ğŸ‘¤ è¯·è¾“å…¥ç”Ÿäº§çº¿æè¿°: ")
        if user_input.strip().lower() in ["exit", "quit"]:
            print("ğŸ‘‹ å†è§ï¼")
            break

        # å…ˆè¿›è¡Œæ–‡æœ¬æ ‡å‡†åŒ–å¤„ç†
        print("ğŸ”„ æ­£åœ¨è¿›è¡Œæ–‡æœ¬æ ‡å‡†åŒ–å¤„ç†...")
        standardized_text = standardize_text(user_input)

        if standardized_text:
            print("âœ… æ–‡æœ¬æ ‡å‡†åŒ–å®Œæˆï¼")
            print(f"æ ‡å‡†åŒ–åçš„æ–‡æœ¬: {standardized_text}")
            processed_text = standardized_text
        else:
            print("âš ï¸  æ ‡å‡†åŒ–å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬")
            processed_text = user_input

        # åˆ›å»ºå¾ªç¯ç”¨äºæ”¯æŒç”¨æˆ·ç¡®è®¤æµç¨‹
        confirmed = False
        current_graph = None
        while not confirmed:
            conversation_history.append({"role": "user", "content": user_input})
            dynamic_prompt = prompt_generator.generate_dynamic_prompt(user_input)
            print(dynamic_prompt)

            # æ„é€ è¯·æ±‚æ¶ˆæ¯
            messages = [{"role": "system", "content": dynamic_prompt}]
            messages.extend(conversation_history)

            try:
                print("â³ æ­£åœ¨ç”Ÿæˆæœ‰å‘å›¾æ•°æ®ç»“æ„...")
                result = make_api_request(messages)
                reply = result["choices"][0]["message"]["content"]

                conversation_history.append({"role": "assistant", "content": reply})

                if DEBUG_MODE:
                    print("\nAIå®Œæ•´å“åº”:")
                    print(reply)
                    print()

                print("ğŸ” æå–æ¨¡å‹æ•°æ®ç»“æ„...")
                graph_data = extract_json_from_response(reply)

                # æ£€æŸ¥APIå›å¤æ˜¯å¦æ˜¯è¯¢é—®è€Œä¸æ˜¯JSON
                if not graph_data and (
                    "?" in reply or "è¯·" in reply or "éœ€è¦" in reply or "ç¼ºå°‘" in reply
                ):
                    print("\nâ“ éœ€è¦è¡¥å……ä¿¡æ¯:")
                    print(reply)
                    user_input = input("ğŸ‘¤ è¯·è¡¥å……ç›¸å…³ä¿¡æ¯: ")  # æ¥æ”¶è¡¥å……ä¿¡æ¯
                    # ç§»é™¤åˆšæ·»åŠ çš„ç”¨æˆ·è¾“å…¥ï¼Œå› ä¸ºéœ€è¦æ›¿æ¢ä¸ºæ–°çš„è¡¥å……ä¿¡æ¯
                    conversation_history.pop()
                    continue

                if graph_data:
                    print("âœ… æˆåŠŸè§£ææœ‰å‘å›¾æ•°æ®ç»“æ„ï¼")

                    # å¤„ç†å¹¶éªŒè¯å›¾æ•°æ®
                    print("ğŸ” å¤„ç†å¹¶éªŒè¯å›¾æ•°æ®ç»“æ„...")
                    is_valid, process_msg, processed_graph = (
                        ProductionLineVisualizer.process_and_validate_graph_data(
                            graph_data
                        )
                    )
                    if not is_valid:
                        print(f"âŒ å›¾æ•°æ®ç»“æ„æ— æ•ˆ: {process_msg}")
                        print("è¯·æ£€æŸ¥è¾“å…¥æè¿°æˆ–APIå“åº”æ ¼å¼")
                        break

                    print(process_msg)
                    graph_data = processed_graph  # ä½¿ç”¨å¤„ç†åçš„å›¾æ•°æ®

                    print("ğŸ”„ æ£€æŸ¥å®¹é‡ä¸º0çš„ä¼ é€å™¨èŠ‚ç‚¹...")
                    graph_data = convert_zero_capacity_conveyors_to_edges(graph_data)
                    print("âœ… æˆåŠŸå¤„ç†å®¹é‡ä¸º0çš„ä¼ é€å™¨èŠ‚ç‚¹")

                    print("æå–çš„JSONæ•°æ®:")
                    print(json.dumps(graph_data, indent=2, ensure_ascii=False))

                    # æ–°å¢ï¼šåˆå§‹åŒ–å­—ä½“é…ç½®
                    ProductionLineVisualizer.initialize_fonts(print_fonts=False)

                    # æ›¿æ¢åŸæœ‰å¯è§†åŒ–ä»£ç ä¸ºç¡®è®¤æµç¨‹
                    print("ğŸ“Š æ­£åœ¨å¯è§†åŒ–å¹¶ç¡®è®¤æœ‰å‘å›¾...")
                    confirmed, current_graph = visualize_and_confirm(
                        graph_data, conversation_history
                    )

                    if not confirmed:
                        # è·å–ç”¨æˆ·æœ€æ–°ä¿®æ”¹æ„è§
                        user_input = conversation_history[-1]["content"]
                        # ä¿ç•™å¯¹è¯å†å²ä½†é‡ç½®å½“å‰å¾ªç¯çŠ¶æ€
                        continue
                    else:
                        # ç”¨æˆ·ç¡®è®¤åè·³å‡ºç¡®è®¤å¾ªç¯
                        break
                else:
                    print("âŒ æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSONæ•°æ®")
                    print("åŸå§‹APIå“åº”:")
                    print(reply)
                    break

            except Exception as e:
                print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                break

        # ç¡®è®¤åç»§ç»­ç”Ÿæˆæ¨¡å‹ä»£ç 
        if confirmed and current_graph:
            print("â³ æ­£åœ¨ç”ŸæˆPlant Simulationä»£ç ...")
            model_setup_code, data_writing_code = json_to_simtalk(current_graph)

            print("\nç”Ÿæˆçš„æ¨¡å‹å»ºç«‹ä»£ç :")
            print(model_setup_code)
            print("\nç”Ÿæˆçš„æ•°æ®å†™å…¥ä»£ç :")
            print(data_writing_code)
            print()

            print("â³ æ­£åœ¨åˆ›å»ºPlant Simulationæ¨¡å‹...")
            if create_plant_simulation_model(model_setup_code, data_writing_code):
                print("ğŸ‰ æ¨¡å‹åˆ›å»ºåŠæ•°æ®å¤„ç†æˆåŠŸï¼Plant Simulationå³å°†å¯åŠ¨...")
            else:
                print("âŒ æ“ä½œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

finally:
    # é‡Šæ”¾COMç¯å¢ƒ
    pythoncom.CoUninitialize()
